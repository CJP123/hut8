{
  
    
        "post0": {
            "title": "Connectionist Temporal Classification (CTC)",
            "content": ". Introduction . This example builds on a couple of great tutorials that demonstrate a simple OCR models. One in Keras by Aakash Kumar Nain and a very helpful conversion to pytorch by Abhishek Thakur. I wanted to get a working knowledge of the CTC loss and also practice using a custom FastAI datablock . !pip install -U fastai --quiet . |████████████████████████████████| 358kB 2.8MB/s . Lets download and look at one of the images from the dataset . from fastai.vision.all import * from itertools import groupby . !curl -LO https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip !unzip -qq captcha_images_v2.zip . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 159 100 159 0 0 228 0 --:--:-- --:--:-- --:--:-- 228 100 8863k 100 8863k 0 0 3719k 0 0:00:02 0:00:02 --:--:-- 17.7M replace captcha_images_v2/ydd3g.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N . Fastai Datablock . This problem requires an ordered target reflecting the characters which is not a default datablock option. I was keen to see how easy it was to generate one that could be used for this problem - the CaptchaBlock . class TensorCaptcha(TensorCategory): pass #Create a Tensor def CaptchaBlock(vocab=None): &quot;`TransformBlock` for Captcha categorical targets&quot; tfm = CaptchaCategorize(vocab=vocab) return TransformBlock(type_tfms=tfm) class CaptchaCategorize(Categorize): &quot;Transform of encoded Captcha-category that decodes with `vocab`&quot; def __init__(self, vocab=None, sort=True, add_na=False): store_attr(self, self.store_attrs+&#39;,sort&#39;) self.vocab = None if vocab is None else CategoryMap(vocab, sort=sort, add_na=add_na) def encodes(self, o): return TensorCaptcha(torch.stack([tensor(self.vocab.o2i[x]) for x in o])) #generates a new tensor encoding the labels def decodes(self, o): return CaptchaCategory((&#39;&#39;).join([Category(self.vocab[x]) for x in o])) #decodes the TensorCaptcha and returns a clean string class CaptchaCategory(L): def show(self, ctx=None, sep=&#39;;&#39;, color=&#39;black&#39;, **kwargs): return show_title(sep.join(self.map(str)), ctx=ctx, color=color, **kwargs) . I am not certain that this code utilises all the fastai functionalyity but it is sufficient for the purposes of this experiment . # . # class TensorCaptcha(TensorCategory): pass #Create a Tensor # class CategorizeCaptcha(Transform): #DisplayedTransform # &quot;Reversible transform of category string to `vocab` id&quot; # loss_func,order,store_attrs=CrossEntropyLossFlat(),1,&#39;vocab,add_na&#39; # def __init__(self, vocab=None, sort=True, add_na=False): # store_attr(self, self.store_attrs+&#39;,sort&#39;) # self.vocab = None if vocab is None else CategoryMap(vocab, sort=sort, add_na=add_na) # def setups(self, dsets): # if self.vocab is None and dsets is not None: self.vocab = CategoryMap(dsets, sort=self.sort, add_na=self.add_na) # self.c = len(self.vocab) # def encodes(self, o): # return TensorCaptcha(torch.stack([tensor(self.vocab.o2i[x]) for x in o])) # def decodes(self, o): # return (&#39;&#39;).join([Category(self.vocab[x]) for x in o])# [dls.vocab[x]) for x in preds] # def CaptchaBlock(vocab=None, sort=True, add_na=False): # &quot;`TransformBlock` to split label into ordered label categorical targets&quot; # return TransformBlock(type_tfms=CategorizeCaptcha(vocab=vocab, sort=sort, add_na=add_na)) . # class Captcha(Transform): #DisplayedTransform # &quot;Reversible transform of category string to `vocab` id&quot; # loss_func,order,store_attrs=CrossEntropyLossFlat(),1,&#39;vocab,add_na&#39; # def __init__(self, vocab=None, sort=True, add_na=False): # store_attr(self, self.store_attrs+&#39;,sort&#39;) # self.vocab = None if vocab is None else CategoryMap(vocab, sort=sort, add_na=add_na) # def setups(self, dsets): # if self.vocab is None and dsets is not None: self.vocab = CategoryMap(dsets, sort=self.sort, add_na=self.add_na) # self.c = len(self.vocab) # def encodes(self, o): # return TensorCaptcha([tensor(self.vocab.o2i[x]) for x in o]) # def decodes(self, o): # return (&#39;&#39;).join([Category(self.vocab[x]) for x in o]) . # tfm = CaptchaBlock(vocab=vocab) # raw = stm(fns[0]) # encoded = tfm(raw) # decoded = tfm.decode(encoded) # assert(raw == decoded) # print(&#39;Input: &#39;, raw) # print(&#39;Encoded: &#39;, encoded) # print(&#39;Decoded: &#39;, decoded) . TypeError Traceback (most recent call last) &lt;ipython-input-208-183eaa3db105&gt; in &lt;module&gt;() 1 tfm = CaptchaBlock(vocab=vocab) 2 raw = stm(fns[0]) -&gt; 3 encoded = tfm(raw) 4 decoded = tfm.decode(encoded) 5 assert(raw == decoded) TypeError: &#39;TransformBlock&#39; object is not callable . Datablock . Set up a new dataloader using the new CaptchaBlock . def stem_label(o): return o.stem . # Set up the required vocab from the filenames titles. # &#39;.&#39; has been added to the front of the vocab to represent the &quot;blank&quot; or null character vocab = L(&#39;.&#39;)+L(set([x for x in (&#39;&#39;).join([x.stem for x in fns])])) vocab . (#20) [&#39;.&#39;,&#39;w&#39;,&#39;m&#39;,&#39;2&#39;,&#39;c&#39;,&#39;7&#39;,&#39;4&#39;,&#39;d&#39;,&#39;n&#39;,&#39;3&#39;...] . captcha = DataBlock(blocks =(ImageBlock(cls=PILImageBW), (CaptchaBlock(vocab=vocab))), get_items=get_image_files, get_y = stem_label, splitter=RandomSplitter(seed=42), item_tfms = Resize((75,300)) ) dls = captcha.dataloaders(path, bs=8) . dls.show_batch(max_n=3) . Look at the resulting tensors for one item . x,y = dls.one_batch() print(x[0],y[0]) . tensor([[[0.7529, 0.7529, 0.7529, ..., 0.9843, 0.9843, 0.9843], [0.7529, 0.7529, 0.7529, ..., 0.9843, 0.9843, 0.9843], [0.7529, 0.7529, 0.7529, ..., 0.9843, 0.9843, 0.9843], ..., [0.7647, 0.7647, 0.7647, ..., 0.9961, 0.9961, 0.9961], [0.7647, 0.7647, 0.7647, ..., 0.9961, 0.9961, 0.9961], [0.7647, 0.7647, 0.7647, ..., 0.9961, 0.9961, 0.9961]]], device=&#39;cuda:0&#39;) tensor([ 8, 8, 19, 14, 19], device=&#39;cuda:0&#39;) . First Model . My first model attempted to largely duplicates the approach and code used by Abhishek . class CaptchaModel(nn.Module): def __init__(self, num_chars=20): super(CaptchaModel, self).__init__() self.conv_1 = nn.Conv2d(1, 128, kernel_size=(3, 3), padding=(1, 1)) self.pool_1 = nn.MaxPool2d(kernel_size=(2, 2)) self.conv_2 = nn.Conv2d(128, 64, kernel_size=(3, 3), padding=(1, 1)) self.pool_2 = nn.MaxPool2d(kernel_size=(2, 2)) self.linear_1 = nn.Linear(1152, 64) self.drop_1 = nn.Dropout(0.2) self.gru_1 = nn.GRU(64, 32, bidirectional=True, num_layers=2, dropout=0.25,batch_first=True) self.output = nn.Linear(64, num_chars) def forward(self, x, targets=None): # bs, c, h, w = x.size() x = F.relu(self.conv_1(x)) # bs, channels , height, width x = self.pool_1(x) x = F.relu(self.conv_2(x)) x = self.pool_2(x) x = x.permute(0, 3, 1, 2) # change the width channel to &#39;time&#39; channel order for input to the RNN x = x.view(x.size(0), x.size(1), -1) x = F.relu(self.linear_1(x)) # x = self.drop_1(x) # x, _ = self.gru_1(x) # x = self.output(x) # x = x.permute(1,0,2) # return x . def ctc_loss(inputs, targets): inputs = inputs.permute(1,0,2) log_probs = F.log_softmax(inputs, 2) input_lengths = torch.full(size=(inputs.size(1),), fill_value=inputs.size(0), dtype=torch.int32) # should be bs x rnn output target_lengths = torch.full(size=(inputs.size(1),), fill_value=tensor(5), dtype=torch.int32) loss = nn.CTCLoss(blank=0)( log_probs, targets, input_lengths, target_lengths ) return loss . # This function is a simple method to reduce duplicate consecutive predictions generated by the CTC loss model. # The following function removes any duplicates in groups but allows duplicates to be separated by the blank placeholder &#39;.&#39; def strip_duplicates(str): return (&#39;&#39;).join([x for x, y in groupby(str) if sum(1 for i in y) &gt;0 if x != &#39;.&#39;]) def show_output(): x,y=dls.valid.one_batch() #get a batch preds = learn.model(x) #get model predictions # preds = preds.permute(1, 0, 2) #permute the model to put the batches in order preds = torch.argmax(torch.softmax(preds, 2), 2) decoded = [(&#39;&#39;).join(dls.vocab[x]) for x in preds] cleaned = [strip_duplicates(x) for x in decoded] results = zip(decoded,cleaned,[(&#39;&#39;).join(dls.vocab[x]) for x in y.detach().cpu().numpy()]) print(&#39;Actual | &#39;,&#39; &#39;*31,&#39;Prediction&#39;,&#39; &#39;*32,&#39;| Cleaned &#39; ) for res in results: print(res[2],&#39; | &#39;,f&#39;{res[0]} | &#39;,&#39;.....&#39; if len(res[1]) == 0 else res[1]) . learn = Learner(dls, CaptchaModel(20), loss_func=ctc_loss, cbs =ReduceLROnPlateau(patience=3)) . learn.lr_find() . SuggestedLRs(lr_min=0.09120108485221863, lr_steep=0.002511886414140463) . Nothing is produced after 50 epochs on the on the validation set. . show_output() . Actual | Prediction | Cleaned 677g3 | .................................................................n.n.n.n.n. | nnnnn wwmn6 | .................................................................n.n.n.n.n. | nnnnn nybcx | .................................................................n.n.n.n.n. | nnnnn y866y | .................................................................n.n.n.n.n. | nnnnn fnbfw | .................................................................n.n.n.n.n. | nnnnn pg2yx | .................................................................n.n.n.n.n. | nnnnn n7g4f | .................................................................n.n.n.n.n. | nnnnn pcm7f | .................................................................n.n.n.n.n. | nnnnn . CNN Only Model . The model above combines a CNN and RNN. The CNN is permuted and reshaped before entering the RNN so that it already should have some sense of &quot;time&quot; order to feed into the CTC loss even without the RNN. This model will remove the RNN from the model and see if can still learn. . class CaptchaModel2(nn.Module): def __init__(self, num_chars=20): super(CaptchaModel2, self).__init__() self.conv_1 = nn.Conv2d(1, 128, kernel_size=(3, 3), padding=(1, 1)) self.pool_1 = nn.MaxPool2d(kernel_size=(2, 2)) self.conv_2 = nn.Conv2d(128, 64, kernel_size=(3, 3), padding=(1, 1)) self.pool_2 = nn.MaxPool2d(kernel_size=(2, 2)) self.drop_1 = nn.Dropout(0.2) self.linear_1 = nn.Linear(1152, 128) self.output = nn.Linear(128, num_chars) def forward(self, x, targets=None): x = F.relu(self.conv_1(x)) # bs, channels , height, width x = self.pool_1(x) x = F.relu(self.conv_2(x)) x = self.pool_2(x) x = x.permute(0, 3, 1, 2) # change the width channel to , h, c x = x.view(x.size(0),x.size(1),-1) # 16, 50, 768 bs, w, hc x = F.relu(self.linear_1(x)) # 16, 50, 128 bs, w, hc x = self.drop_1(x) # 16, 50, 19+1 bs, w, hc x = self.output(x) # 16, 50, 19+1 bs, w, hc return x . learn = Learner(dls, CaptchaModel2(20), loss_func=ctc_loss, cbs=ReduceLROnPlateau(patience=3)) . learn.lr_find() . SuggestedLRs(lr_min=0.03019951581954956, lr_steep=0.0003981071640737355) . learn.fit(50,1e-3) . epoch train_loss valid_loss time . 0 | 0.373616 | 0.335259 | 00:02 | . 1 | 0.378223 | 0.287420 | 00:02 | . 2 | 0.338104 | 0.272776 | 00:02 | . 3 | 0.318468 | 0.272740 | 00:02 | . 4 | 0.328818 | 0.263506 | 00:02 | . 5 | 0.305960 | 0.263038 | 00:02 | . 6 | 0.301829 | 0.281372 | 00:02 | . 7 | 0.285233 | 0.262878 | 00:02 | . 8 | 0.293329 | 0.247991 | 00:02 | . 9 | 0.293683 | 0.252269 | 00:02 | . 10 | 0.273322 | 0.278389 | 00:02 | . 11 | 0.254602 | 0.276594 | 00:02 | . 12 | 0.212496 | 0.226679 | 00:02 | . 13 | 0.189272 | 0.230855 | 00:02 | . 14 | 0.198126 | 0.227599 | 00:02 | . 15 | 0.189863 | 0.228974 | 00:02 | . 16 | 0.187685 | 0.227659 | 00:02 | . 17 | 0.202192 | 0.227266 | 00:02 | . 18 | 0.192485 | 0.226430 | 00:02 | . 19 | 0.190232 | 0.227033 | 00:02 | . 20 | 0.189776 | 0.224058 | 00:02 | . 21 | 0.186851 | 0.226305 | 00:02 | . 22 | 0.187045 | 0.224353 | 00:02 | . 23 | 0.193822 | 0.223141 | 00:02 | . 24 | 0.199574 | 0.224017 | 00:02 | . 25 | 0.187568 | 0.225407 | 00:02 | . 26 | 0.186910 | 0.225330 | 00:02 | . 27 | 0.191695 | 0.225298 | 00:02 | . 28 | 0.193181 | 0.225424 | 00:02 | . 29 | 0.198716 | 0.225431 | 00:02 | . 30 | 0.190997 | 0.225408 | 00:02 | . 31 | 0.190925 | 0.225385 | 00:02 | . 32 | 0.185933 | 0.225379 | 00:02 | . 33 | 0.185405 | 0.225380 | 00:02 | . 34 | 0.188094 | 0.225379 | 00:02 | . 35 | 0.183973 | 0.225379 | 00:02 | . 36 | 0.181050 | 0.225379 | 00:02 | . 37 | 0.194128 | 0.225379 | 00:02 | . 38 | 0.192394 | 0.225379 | 00:02 | . 39 | 0.197801 | 0.225379 | 00:02 | . 40 | 0.185498 | 0.225379 | 00:02 | . 41 | 0.179554 | 0.225379 | 00:02 | . 42 | 0.177688 | 0.225379 | 00:02 | . 43 | 0.179876 | 0.225379 | 00:02 | . 44 | 0.189544 | 0.225379 | 00:02 | . 45 | 0.190421 | 0.225379 | 00:02 | . 46 | 0.191165 | 0.225379 | 00:02 | . 47 | 0.182564 | 0.225379 | 00:02 | . 48 | 0.180183 | 0.225379 | 00:02 | . 49 | 0.189621 | 0.225379 | 00:02 | . Epoch 11: reducing lr to 0.0001 Epoch 15: reducing lr to 1e-05 Epoch 26: reducing lr to 1.0000000000000002e-06 Epoch 29: reducing lr to 1.0000000000000002e-07 Epoch 32: reducing lr to 1.0000000000000002e-08 Epoch 35: reducing lr to 1.0000000000000003e-09 Epoch 38: reducing lr to 1.0000000000000003e-10 Epoch 41: reducing lr to 1.0000000000000003e-11 Epoch 44: reducing lr to 1.0000000000000002e-12 Epoch 47: reducing lr to 1.0000000000000002e-13 . show_output() . Actual | Prediction | Cleaned 677g3 | .................6...77......7..........g......3........................... | 677g3 wwmn6 | ............w........ww.....................n.......6...................... | wwn6 nybcx | ............n........yy.....bb..........cc......x.......................... | nybcx y866y | ..............y...........8........6.......66....y......................... | y866y fnbfw | .............f.............b.........f......w.............................. | fbfw pg2yx | ............p............g...2.......yy..........x......................... | pg2yx n7g4f | .....................7..........g.......4.....f............................ | 7g4f pcm7f | ............p...........cc.......nn.......7......f......................... | pcn7f .",
            "url": "https://cjp123.github.io/hut8/2020/08/28/_08_27_Captcha_Fastai_DataBlock_and_CTC_Loss.html",
            "relUrl": "/2020/08/28/_08_27_Captcha_Fastai_DataBlock_and_CTC_Loss.html",
            "date": " • Aug 28, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://cjp123.github.io/hut8/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://cjp123.github.io/hut8/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://cjp123.github.io/hut8/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://cjp123.github.io/hut8/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}